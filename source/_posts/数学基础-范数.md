---
mathjax: true
title: 数学基础-范数
date: 2021-10-29 14:07:26
tags:
- 数学基础
categories: 
- 数学基础
---

数学中范数概念

<!--more-->

# 范数

我们知道距离的定义是一个宽泛的概念，只要满足非负、自反、三角不等式就可以称之为距离。范数是一种强化了的距离概念，它在定义上比距离多了一条数乘的运算法则。有时候为了便于理解，我们可以把范数当作距离来理解。

在数学上，范数包括向量范数和矩阵范数，向量范数表征向量空间中向量的大小，矩阵范数表征矩阵引起变化的大小。**一种非严密的解释**就是，对应向量范数，向量空间中的向量都是有大小的，这个大小如何度量，就是用范数来度量的，不同的范数都可以来度量这个大小，就好比米和尺都可以来度量远近一样；对于矩阵范数，学过线性代数，我们知道，通过运算$AX=B$，可以将向量$X$变化为$B$，矩阵范数就是来度量这个变化大小的。

对于一个向量$x=(x_1,x_2,\cdots,x_n)$,其各种范数描述如下

## L1范数

$$
\Vert x\Vert_{1}=\sum\limits_{i=1}^{n}\vert x_i\vert
$$

即向量元素绝对值之和。在numpy中调用:

```python
import numpy as np
np.linalg.norm(x,ord=1)
```

## L2范数

$$
\Vert x\Vert_{2}=\sqrt{\sum\limits_{i=1}^{n}x_i^2}
$$

Euclid范数（欧几里得范数，常用计算向量长度），即向量元素绝对值的平方和再开方。在numpy中调用:

```python
import numpy as np
np.linalg.norm(x,ord=2)
```

## P范数

$$
\Vert x\Vert_{p}=\left(\sum\limits_{i=1}^{n}\vert x_i\vert^{p}\right)^{\frac{1}{p}}
$$
在numpy中调用:
```python
import numpy as np
np.linalg.norm(x,ord=p)
```

## L-$\infty$范数

### L-$+\infty$

$$
\Vert x\Vert_{+\infty}=\mathop{max}\limits_i(\vert x_i\vert)
$$

即所有向量元素绝对值中的最大值。在numpy中调用:
```python
import numpy as np
np.linalg.norm(x,ord=np.inf)
```
### L-$-\infty$
$$
\Vert x\Vert_{-\infty}=\mathop{min}\limits_i(\vert x_i\vert)
$$

即所有向量元素绝对值中的最小值。在numpy中调用:
```python
import numpy as np
np.linalg.norm(x,ord=-np.inf)
```
# 闵可夫斯基距离（Minkowski distance）

距离度量的性质：

- 非负性：$\text{dist}(x_i,x_j)\geq 0$
- 同一性：$\text{dist}(x_i,x_j)=0$,当且仅当$x_i=x_j$
- 对称性：$\text{dist}(x_i,x_j)=\text{dist}(x_j,x_i)$
- 直递性：$\text{dist}(x_i,x_j)\leq\text{dist}(x_i,x_k)+\text{dist}(x_k,x_j)$

给定样本$x_i=(x_{i1},x_{i2},\dots,x_{in}),x_j=(x_{i1},x_{i2},\dots,x_{in})$,最常用的求距离的方法
$$
\text{dist}_{\text{mk}}(x_i,x_j)=\left( 
\sum\limits_{u=1}^{n}\vert x_{iu}-x_{ju}\vert^{p}
\right )^{\frac{1}{p}}
$$
​		$p=2$时，闵可夫斯基距离即是欧式距离(Euclidean distance)
$$
\text{dist}_{\text{ed}}(x_i,x_j)=\Vert x_i-x_j\Vert_{2}=\sqrt{\sum\limits_{u=1}^{n}\vert x_{iu}-x_{ju}\vert ^{2}}
$$
​		$p=1$时，闵可夫斯基距离即是曼哈顿距离(Manhattan distance)
$$
\text{dist}_{\text{man}}(x_i,x_j)=\Vert x_i-x_j\Vert_{1}=\sum\limits_{u=1}^{n}\vert x_{iu}-x_{ju}\vert
$$
